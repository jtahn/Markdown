[53. Maximum Subarray](https://leetcode.com/problems/maximum-subarray/)

```
class Solution:
    def maxSubArray(self, nums: List[int]) -> int:
        
```

Given an integer array `nums`, find the subarray with the largest sum, and return _its sum_.
A subarray is a contiguous non-empty sequence of elements within an array.

**Example 1:**  
**Input:** `nums = [-2,1,-3,4,-1,2,1,-5,4]`  
**Output:** `6`  
**Explanation:** `The subarray [4,-1,2,1] has the largest sum 6.`  

**Example 2:**  
**Input:** `nums = [1]`  
**Output:** `1`  
**Explanation:** `The subarray [1] has the largest sum 1.`  

**Example 3:**  
**Input:** `nums = [5,4,-1,7,8]`  
**Output:** `23`  
**Explanation:** `The subarray [5,4,-1,7,8] has the largest sum 23.`  

**Constraints:**
- $1 \leq \texttt{nums.length} \leq 10^5$
- $-10^4 \leq \texttt{nums[i]} \leq 10^4$

**Follow up:** If you have figured out the `O(n)` solution, try coding another solution using the **divide and conquer** approach, which is more subtle.

---
# Brute force
- check every sub-array; count $\binom{n}{2} + n =O(n^2)$
	- subarray corresp to its endpoints; which corresp pair of indices
		- $\binom{n}{2}$ combos of 2 distinct indices
		- $n$ 'combos' of 2 same indices; aka 1 element subarray
- complexity
	- $O(n^3)$ time
		- for each sub-array, takes O(n) to compute sum
	- $O(1)$ space

![](../!assets/attachments/Pasted%20image%2020240315181230.png)


# Dynamic programming
```
def maxSubArray(self, nums: List[int]) -> int:
	dp = [0] * len(nums)
	for i,num in enumerate(nums):
		dp[i] = num + max(dp[i-1], 0)
	return max(dp)
```
- observations
	- let `dp[j]` be the max sum from subarrays with right endpoint `j`
		- i.e. subarrays of the form `nums[i:j]`
	- the solution to the problem is `max(dp)`
	- we can compute `dp` in one pass
		- because `dp[j]` is either:
			- `nums[j]`
			- `nums[j] + dp[j-1]`
				- i.e. append it to the max subarray ending at `j-1`
			- i.e. `dp[j]` needs to include `nums[j]` for sure; and you just add `dp[j-1]` if it is non-negative
				- if `dp[i-1]` is negative, then we should the the best sum ending at `i` is just the element itself
				- ie start a new subarray
- complexity
	- $O(n)$ time
		- traversed `nums` once
	- $O(n)$ space

# Kadane's (best)
```
def maxSubArray(self, nums: List[int]) -> int:
    max_right_sum_seen = -math.inf
    max_sum_seen = -math.inf
    for num in nums:
        max_right_sum_seen = num + max(0, max_right_sum_seen)
        max_sum_seen = max(max_sum_seen, max_right_sum_seen)
    return max_sum_seen
```
- observation:
	- we can do the DP solution with O(1) space by modifying the input array (ie in place)
	- better: we can achieve O(1) space without modifying input array. note:
		- `dp[j]` only needs `dp[j-1]`
	- so we don't need the array `dp` from the DP solution
		- all we need is two variables that update:
			- `dp[j-1]`
				- i.e. max over subarrays of the form `nums[i:j-1]`
				- i.e. with right endpoint `j-1`
			- `max(dp[:j-1])`
				- ie max sum from subarrays of `nums[0:j-1]
				- ie solution on `nums[0:j-1]
				- and when we end the loop, this variable has our solution
- strategy
	- loop through array, using variables to track/update:
		- "max subarray sum"
		- "max right subarray sum"
- complexity
	- O(n) time
	- $O(1)$ space
- note
	- this is kadane's algo
	- this algo can be modified to allow empty subarrays
		- something like (todo: confirm this): just have a conditional at the end that returns an empty subarray if the sentinel value (ie `-math.inf`) was the best sum found


# Divide-and-conquer (worse, but important)
```
def main():
	if len(nums) == 0:
		return 0
	else:
		return helper(0, n-1, nums)[2]

def helper(l, r, nums):
		if l == r:
			x = nums[l]
			return (x, x, x, x) 
		m = (l + r) // 2

		l_head, l_tail, l_sub, l_ttl = helper(l, m, nums)
		r_head, r_tail, r_sub, r_ttl = helper(m+1, r, nums)

		head = max(l_head, l_ttl + r_head)
		tail = max(r_tail, l_tail + r_ttl)
		sub = max(l_sub, r_sub, l_tail + r_head)
		ttl = l_ttl + r_ttl

	return head, tail, sub, ttl
```
- note
	- this approach is not optimal
		- time complexity is asymptotically equal, but surely worse constant
		- space complexity is asymptotically worse
		- way more complicated to understand than kadane's
			- kadane's just seems like: realizing that you don't need to do left and right splits..instead can just crawl from left to right (or opposite)
		- worse space complexity bc recursion stack space
	- it is described because it is a classic example of common misunderstandings about divide-and-conquer (and also DP) techniques
		- i.e. it's an example of how the d&c isn't as straightforward as 'find best solution among parts, then pick the better one them or combine them in a really obvious way'
			- bc the issue is that: for this problem, in the combine step: a subarray needs to be contiguous
			- so in general, you can't combine 'solutions' from subarrays
			- this means in the solve step, you need to compute multiple things (ie 'best sum starting from left/right'); not just the 'solution from this part'
		- also see p304-306 of aziz's EPI
			- briefly:
				- ![](../!assets/attachments/Pasted%20image%2020240315181349.png)
				- ![](../!assets/attachments/Pasted%20image%2020240315181407.png)
- complexity
	- O(lg n) space
		- max depth of runtime/recursion stack
	- O(n) time
		- (todo: better names)
			- head sum/max
				- subarray with largest sum, starting from first elt
			- tail sum/max
				- start from last elt
			- ttl sum
				- sum of whole array
			- max sub sum
				- subarray with largest sum
		- many other d&c approaches do not return all of leftMax, rightMax, subMax, and subSum
			- so what ends up always happening: after the current array receives info/'results from subproblems' from its subarrays, it needs to spend linear time in the combine step to 'fill in the gaps'/'solve all parts of its subproblem'
			- ie need to spend O(m) time doing this, where m is size of current array
			- so this is why a lot of solutions are O(n logn) time in total
				- ie recurrence relation `T(n) = 2 T(n/2) + O(n)`
		- for an O(n) time total solution, you need combine step to be constant; and seems this requires the aux function to return all 4 of the above
			- in particular, subSum (full sum of the array) is the key component that many approaches leave out
			- because leftMax and rightMax of current array, need full sums of the left and right subarrays
				- for when leftMax and/or rightMax of current array includes the 'middle' of the current array
			- many solutions
			- and obvi, we want leftMax and rightMax to be provided
		- more details:
			- basically these can all be computed/combined in O(1) time (from the same quantities of left and right subarrays):
				- leftMax, rightMax, max, sum of whole array
					- leftMax is either:
						- left's leftMax of left array
						- left's sum + right's leftMax
					- rightmax is similar
					- max is either:
						- left's leftMax
						- right's rightMax
						- left's rightMax + right's leftMax
					- sum is left's sum + right's sum
			- key observation is that the above 'combine' computations that are a max:  the choice of max is just btwn 2 options: include the middle or not
			- time complexity is O(n) because
				- `T(n) = 2 * T(n/2) + O(1)` implies `T(n) = O(n)`


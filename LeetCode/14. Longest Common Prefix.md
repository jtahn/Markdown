[14. Longest Common Prefix](https://leetcode.com/problems/longest-common-prefix/)

```python
class Solution:
    def longestCommonPrefix(self, strs: List[str]) -> str:
        
```

# Description

Write a function to find the longest common prefix string amongst an array of strings.

If there is no common prefix, return an empty string `""`.

**Example 1:**  
**Input:** `strs = ["flower","flow","flight"]`  
**Output:** `"fl"`  

**Example 2:**  
**Input:** `strs = ["dog","racecar","car"]`  
**Output:** `""`  
**Explanation:** There is no common prefix among the input strings.

**Constraints:**
- `1 <= strs.length <= 200`
- `0 <= strs[i].length <= 200`
- `strs[i]` consists of only lowercase English letters.

---


# todo

- this seems like a great problem to practice complexity analysis
- have a fairly comprehensive/convincing complexity analysis for each approach below


# References

## #ad_hoc 
- https://leetcode.com/problems/longest-common-prefix/solutions/3273176/python3-c-java-19-ms-beats-99-91/
	- this is soooo clever
		- strat
			- lexicographic sort the strings
			- then all you need to compare is the first and last string
	- the percentiles make it seem like this is by far the most efficient in practice
		- but check comments..this might actually strictly worse asymptotically?
			- it seems complexity analysis is lowkey kind of subtle/non-trivial here
		- if indeed it is ‘most efficient on test cases/in practice’ but worse efficiency asymptotically…imo this is something definitely worth observing and pointing out
			- and really understanding why
	- briefly trying to think about asymptotics:
		- sorting is relatively expensive here compared to the ‘naive’ solutions, bc those only require at most 1 linear scan per word
		- might be best asymptotically, if num strings is far higher than max length of a string
	- !!! wait:
		- observe we don’t need a full sort
		- we only need to know what the first and last elt in the sort would be
		- surely can do some kind of modified quickselect here? or at least, some kind of heavily truncated sort
			- !!! linear pass through words, just maintain/update currFirst and currLast word
	- !! actually:
		- tbh makes no sense for this to be asymptotically better. bc even in this 'optimized sort/select', we are essentially doing the exact same loops that are performed in the 'vertical scan' strat.
		- HOWEVER: why it might be faster in practice:
			- i highly suspect it's purely bc of how python works
				- when you do the lexicographic sort/select, you can use the `<=` operator which i think you can probly consider the equivalent of: these comparison/'loops' is done with the optimized C code
					- ie very easy + builtin way to access 'low level' performance
					- ie instead of having to use numba or cython
				- versus the horizontal/vertical scan approaches: all these loops are python loops
			- so basically this might just boil down to:
				- an approach that mostly uses C loops instead of python loops, might still be faster, even if it has worse complexity



# Strategies

## vertical scan
- strat:
	- compare first 2 strings, figure out common prefix `currCommon`
	- then figure out common prefix btwn `currCommon` and `string3`
	- and so on…
- complexity?

## horizontal scan
- https://algo.monster/liteproblems/14
- strat
	- for each index, compare chars with all strings


## sort then compare first and last
- strat: see adhoc above
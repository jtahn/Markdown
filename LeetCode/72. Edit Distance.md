[72. Edit Distance](https://leetcode.com/problems/edit-distance/)

```python
class Solution:
    def minDistance(self, word1: str, word2: str) -> int:
        
```

# Description

Given two strings `word1` and `word2`, return _the minimum number of operations required to convert `word1` to `word2`_.

You have the following three operations permitted on a word:
- Insert a character
- Delete a character
- Replace a character

**Example 1:**  
**Input:** `word1 = "horse", word2 = "ros"`  
**Output:** `3`  
**Explanation:**  
```
horse -> rorse (replace 'h' with 'r')
rorse -> rose (remove 'r')
rose -> ros (remove 'e')
```

**Example 2:**  
**Input:** `word1 = "intention", word2 = "execution"`  
**Output:** `5`  
**Explanation:**  
```
intention -> inention (remove 't')
inention -> enention (replace 'i' with 'e')
enention -> exention (replace 'n' with 'x')
exention -> exection (replace 'n' with 'c')
exection -> execution (insert 'u')
```

**Constraints:**
- `0 <= word1.length, word2.length <= 500`
- `word1` and `word2` consist of lowercase English letters.

---

# todo

#/future
- [Don't watch my A2Z DSA Course - YouTube](https://www.youtube.com/watch?v=0bHoB32fuj0)
- https://web.stanford.edu/class/cs124/
- topics
	- language processing
	- https://en.wikipedia.org/wiki/Prompt_engineering


#/strats
- i think for some of these harder DP problems, definitely have to top-down recursive dp solution
	- i bet it's actually very easy to code once i have/practice a few examples
		- esp bc the python `@cache` decorater exists
		- have a few examples that use decorate and do manually

#/move  this fundy somewhere

## #python/decorator/cache
- https://realpython.com/primer-on-python-decorators/#caching-return-values
- https://realpython.com/lru-cache-python/#using-memoization-to-improve-the-solution



# References

## #dynamic_programming 
- https://algo.monster/liteproblems/72
- https://www.youtube.com/watch?v=fJaKO8FbDdo
	- 11:00
		- define subproblems
			- `f(i,j) = min ops to convert word1[:i] to word2[:j]`
			- then recurrence is obvious:
				- if `word1[i] == word2[j]`:
					- then `f(i,j) = f(i-1,j-1)`
					- bc no need to do extra ops
				- if `word1[i] != word2[j]`:
					- then number of ops for each action (on `word1`) based on 'subproblems with at most 1 backward action per axis'
					- or actually maybe it's like:
						- we look at min ops for each case where the last action is different; and then we take the min over these options
						- !!! yea this is what makes the options below easier to understand, esp for 'insert'
							- if you want 'insert' to be the last action:
								- btw maybe #/fundy...should i think of 'insert' as rather and 'append'/'add' operation?
							- then it's obvious that you need to know how to turn `word1[i]` into `word2[j-1]`
					- anyways the options:
						- insert: `1 + f(i,j-1)`
							- insert the character at `word1[i+1]` that matches `word2[j]`
							- so now you just need min steps to get `word1[i]` to look like `word2[j-1]`, aka `f(i,j-1)`
						- delete: `1 + f(i-1,j)`
						- replace: `1 + f(i-1,j-1)`
							- if you want 'replace' to be the last action, then you need `word1[i-1]` to match `word2[j-1]`
							- aka replace char at `word1[i]` with `word2[j]`
					- and now just take min of the above
					- #/fundy i think insert/delete/replace being 'last step you do'...this is the idea of 'single backward action along an axis'
						- replace seems interesting bc it's making me think:
							- i should focus on backward action, not axis
							- bc this action actually goes backward on both axes
					- also #/fundy 
						- the way the subp for each 'backward action' will contribute to solution...seems very obvious actually:
							- extrema problem: take extrema over each possible action
							- count/accumulate problem: accumulate over each possible action (often sum them)
					- !!! #/fundy 
						- why it makes sense to consider each 'backward action':
						- remember that observation i had about dp being like...filling out 'state space' instead searching through 'candidate space'
						- and so point is: 'backward action' is like:
							- consider 'all candidates that ended with this action'
							- then we know they 'came from this state'
							- so go pull from that state
			- base cases
				- it's when we're at 'empty strings'
				- so i or j is `-1`
					- btw #/fundy this seems like a big benefit of the `f(i,j)` notation over `dp[i][j]`
						- bc technically `dp[-1][-1] = dp[n][m]` which isn't what we're talking about
				- we have `f(-1,j) = j+1`
					- aka just add all the chars...there are `j+1` of them
				- and `f(i,-1) = i+1`
					- delete all the chars
				- maybe #/fundy: if your recurrence relation has too many conditions...maybe it just means you don't have enough base cases
					- note how comprehensive we are with base cases here
						- ie we didn't make `f(-1,-1)` be the only base case
					- by being very comprehensive about all the base cases, we don't really need to put any more conditions on the recurrence relation above
						- aka it works on any subproblem that isn't a base case
						- ie we didn't have to add any extra logic about situations where it's "invalid" to insert/delete/replace chars
	- at each step: based on certain conditions: we can do certain actions
		- #/fundy definitely an observation to point out about dp
			- aka the available actions can change based on the input
		- 7:45 here, at each index:
			- if unequal:
				- insert, replace, delete
			- if equal
				- based on equality, we can do some of the 
			- 11:45 #/fundy
				- when working with two strings:
					- if it's a "string matching"-type problem
					- then the standard conditions that inform actions:
						- 2 possible: iterators match/equal or not equal
		- i think the above fundies will actually start making DP code very obvious (if i write it well)
			- so no real need to have these explanations probly..or they can be significantly abbreviated
				- basically only need explanations for when applying a fundy really does require some extra thinking
			- i just need to remember the fundeez: subp solns involve:
				- figure out condition
				- figure out 'valid actions' for that condition
				- compute soln via recurrence relations involving 'single backward valid actions along each axis'
	- #/jargon/dp tUf often uses `f(i,j)` notation instead of `dp[i][j]`
		- i think bc he's working with recurrence relation/function, and this is standard notation (either in theory/texts, or in competitive programming scene)
		- confirm whether this jargon is standard, and whether i should use this jargon instead of the 'array' jargon
		- check clrs/skiena too
		- i think it might depend on whether ppl think 'recurrence' is the fundamental/underlying thing for 'dynamic programming'
			- 

	- 22:30 complexity analysis
	- 24:00 coding (top-down probly)
		- i tihnk #/fundy will probably be:
			- if base case involves `-1`, then `dp[i][j]` needs to shift all the above definitions
				- bc we want base case to now involve `0` when we code
	- 27:00 tabulation; bottom-up
	- 33:00 1d space optimization



- https://web.stanford.edu/class/cs124/lec/med.pdf
- https://drive.google.com/file/d/1lj7S3x_Yl01kTeGPKMfVpEfHf_ubZ5V5/view



# Strategies



## dynamic programming



```python
# neetcode
class Solution:
    def minDistance(self, word1: str, word2: str) -> int:
        dp = [[float("inf")] * (len(word2) + 1) for i in range(len(word1) + 1)]

        for j in range(len(word2) + 1):
            dp[len(word1)][j] = len(word2) - j
        for i in range(len(word1) + 1):
            dp[i][len(word2)] = len(word1) - i

        for i in range(len(word1) - 1, -1, -1):
            for j in range(len(word2) - 1, -1, -1):
                if word1[i] == word2[j]:
                    dp[i][j] = dp[i + 1][j + 1]
                else:
                    dp[i][j] = 1 + min(dp[i + 1][j], dp[i][j + 1], dp[i + 1][j + 1])
        return dp[0][0]

```



## math
- (tbh this strat idea seems useless...meat of the problem is DP anyways)
	- so maybe just scrap/delete this
- i bet there's a math+dp solution
	- compute differences in length
		- this probly is number of additions/deletions you need
	- find L = length of longest common subseq
		- then len(word2)-L is probly the number of replacements you need
	- (proof..this is probly where 'math' comes in):
		- above process is def an upper bound on number of ops required
		- also a lower bound
			- add/deletion is obvious
			- replacements...idk atm, but can probly figure it out

[329. Longest Increasing Path in a Matrix](https://leetcode.com/problems/longest-increasing-path-in-a-matrix/)

```python
class Solution:
    def longestIncreasingPath(self, matrix: List[List[int]]) -> int:
        
```

# Description

Given an `m x n` integers `matrix`, return _the length of the longest increasing path in_ `matrix`.

From each cell, you can either move in four directions: left, right, up, or down. You **may not** move **diagonally** or move **outside the boundary** (i.e., wrap-around is not allowed).

**Example 1:**  
![](!assets/attachments/Pasted%20image%2020240418150434.png)  
**Input:** `matrix = [[9,9,4],[6,6,8],[2,1,1]]`  
**Output:** `4`  
**Explanation:** The longest increasing path is `[1, 2, 6, 9]`.

**Example 2:**  
![](!assets/attachments/Pasted%20image%2020240418150445.png)  
**Input:** `matrix = [[3,4,5],[3,2,6],[2,2,1]]`  
**Output:** `4`  
**Explanation:** The longest increasing path is `[3, 4, 5, 6]`. Moving diagonally is not allowed.

**Example 3:**  
**Input:** `matrix = [[1]]`  
**Output:** `1`  

**Constraints:**
- `m == matrix.length`
- `n == matrix[i].length`
- `1 <= m, n <= 200`
- `0 <= matrix[i][j] <= 2^31 - 1`

---


# todo
#/jargon 
- does 'caching' = 'memoization'?
- and what is 'tabulating'?




#/style 
- maybe include 'alt' interpretations?
	- bc then i have examples of how to turn the 'alt' interpretation into the 'true inspo'


#/fundy
- this seems like a useful observation to mention, but idk where to put it or how i should abstract it
	- 'base cases' seem useless in this problem
		- ie nodes that are local maxes, the path is just itself
			- and it's easy to pass through the array to determine which nodes are local maxes
		- however it seems this info doesn't help us at all
			- like knowing that a node is a 'base case', doesn't immediately tell us about the 'longest increasing path' of its neighbors
			- aka COMPLETELY different from 'shortest path'
				- bc then we could just trivially do bfs
	- i think the idea/abstraction/related concepts are:
		- 'base cases' might not be helpful at all with determining subproblem structure
			- so maybe figure these out last
			- aka always try to focus first on: are there redundant computations that we are doing?
		- 'dp' seems more about the abstract idea of storing results so you don't need to recompute
			- in a bunch of prev problems, there were ways to do this incredibly cleanly, and could even do it via bottom-up and often by not storing all results
			- but nbd if you just do top-down: still lots of savings
			- here it seems
				- #/strats if bottom-up isn't possible here and/or worse complexity, understand why
					- should be possible though...iirc bottom-up always possible 



#/strats 
- there are other strats, but unimportant for now
	- the dp strat is optimal, and is an important example of how dp is still very valuable even at it's worst
	- [Longest Increasing Path in a Matrix - LeetCode](https://leetcode.com/problems/longest-increasing-path-in-a-matrix/solutions/288520/longest-path-in-dag/)
	- [Longest Increasing Path in a Matrix - LeetCode](https://leetcode.com/problems/longest-increasing-path-in-a-matrix/solutions/1429348/c-python-2-solutions-dfs-memoization-topology-sort-peel-onion-clean-concise/)
	- [Longest Increasing Path in a Matrix - LeetCode](https://leetcode.com/problems/longest-increasing-path-in-a-matrix/solutions/2052444/4-approaches-bfs-memorization-dfs-dp-topo-sorting/)



- for dp memo soln, make sure i have code for both
	- python `@cache` decorator
	- manual cache



# References

## #dynamic_programming/memoization 
- https://www.youtube.com/watch?v=wCc_nd-GiEc&list=PLPe9IkX86X3y5m_MvtNu2ughxsvkqUNKr&index=117
- https://algo.monster/liteproblems/329
- 

- this might be a good examples for when dp doesn't feel like the 'main/initial technique' in a problem
	- ie the real takeaways from dp should be:
		- recognizing when you:
			- are doing redundant work
			- can use previous solutions to build new solutions
		- and how to implement 'dp type' optimizations/strats when you recognize the above
- bc here:
	- feels like the 'main/initial strat' is to just run a traversal on every node
	- then you realize a few things:
		- determining the LIP starting at the node, also determines the LIP for every node along that path
			- i think this means: if we cache, then it's 'top-down'
			- also basically shows why each node is visited once
				- #/fundy is this like a general thing that happens?
					- ie using caching with a traversal ends up letting you 'only visit each node once', even for problems where you essentially/initially want to start a traversal at each node?
		- if x is considering adding y to its candidate LIP, and you already know LIP at y:
			- then you know exactly the contribution to x's LIP by adding y
				- and it is valid to add y's LIP
					- nothing in y's LIP can be in x's candidate LIP, bc everything before y had to be smaller; and everything in y's LIP is bigger
					- ie y's LIP doesnt contain stuff in x's candidate LIP
			- aka we can use optimal substructure


- feels different from past dp problems i've done
	- bc there doesn't seem to be like a 'obvious way to go from smaller to larger subproblems'
	- most prev problems:
		- the 'smaller subproblems' are exactly those that have 'smaller answers/values'
		- and there is like a clear way to iterate over the 'smaller subproblems' before 'larger subproblems'

- caching means that we only solve each subproblem once
	- aka each node is only 'visited' once
	- so this algo is actually really efficient






## #graphs/topological_sort 
- https://leetcodethehardway.com/solutions/0300-0399/longest-increasing-path-in-a-matrix-hard#approach-2-topological-sort
	- approach 2



## #array/traversal/neighbors 

coding trick
```python
DIR = [0, 1, 0, -1, 0]
for i in range(4):
	nr, nc = r + DIR[i], c + DIR[i+1]
	if nr < 0 or nr == m or nc < 0 or nc:
		continue  # Out of bounds
```



## #python/decorator/cache 




# Results





# Strategies



## dfs with memoization
```python
# neetcode
class Solution:
    def longestIncreasingPath(self, matrix: List[List[int]]) -> int:
        ROWS, COLS = len(matrix), len(matrix[0])
        dp = {}  # (r, c) -> LIP

        def dfs(r, c, prevVal):
            if r < 0 or r == ROWS or c < 0 or c == COLS or matrix[r][c] <= prevVal:
                return 0
            if (r, c) in dp:
                return dp[(r, c)]

            res = 1
            res = max(res, 1 + dfs(r + 1, c, matrix[r][c]))
            res = max(res, 1 + dfs(r - 1, c, matrix[r][c]))
            res = max(res, 1 + dfs(r, c + 1, matrix[r][c]))
            res = max(res, 1 + dfs(r, c - 1, matrix[r][c]))
            dp[(r, c)] = res
            return res

        for r in range(ROWS):
            for c in range(COLS):
                dfs(r, c, -1)
        return max(dp.values())

```
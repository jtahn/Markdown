[153. Find Minimum in Rotated Sorted Array](https://leetcode.com/problems/find-minimum-in-rotated-sorted-array/)

```
class Solution:
    def findMin(self, nums: List[int]) -> int:
        
```

# Description
Suppose an array of length `n` sorted in ascending order is **rotated** between `1` and `n` times. For example, the array `nums = [0,1,2,4,5,6,7]` might become:

- `[4,5,6,7,0,1,2]` if it was rotated `4` times.
- `[0,1,2,4,5,6,7]` if it was rotated `7` times.

Notice that **rotating** an array `[a[0], a[1], a[2], ..., a[n-1]]` 1 time results in the array `[a[n-1], a[0], a[1], a[2], ..., a[n-2]]`.

Given the sorted rotated array `nums` of **unique** elements, return _the minimum element of this array_.

You must write an algorithm that runs in `O(log n) time.`

**Example 1:**  
**Input:** `nums = [3,4,5,1,2]`  
**Output:** `1`  
**Explanation:** The original array was `[1,2,3,4,5]` rotated 3 times.  

**Example 2:**  
**Input:** `nums = [4,5,6,7,0,1,2]`  
**Output:** `0`  
**Explanation:** The original array was `[0,1,2,4,5,6,7]` and it was rotated 4 times.  

**Example 3:**  
**Input:** `nums = [11,13,15,17]`  
**Output:** `11`  
**Explanation:** The original array was `[11,13,15,17]` and it was rotated 4 times.  

**Constraints:**
- `n == nums.length`
- `1 <= n <= 5000`
- `-5000 <= nums[i] <= 5000`
- All the integers of `nums` are **unique**.
- `nums` is sorted and rotated between `1` and `n` times.

---

# References
## binary search general
- 'I think it's best to think about the binary search conditions (for any problem that uses it) in terms of which parts of the array get disqualified for the next iteration.'
- The primary objective of the Binary Search algorithm is to efficiently determine the appropriate half to eliminate, thereby reducing the search space by half. It does this by determining a specific condition that ensures that the target is not present in that half.



## binary search: return mid
- aka valid vs 'best valid'
- aka 2 vs 3 cases

- if you're trying to find something that meets a 'criteria' (ie the smallest value (that does X))...then generally you use 2 cases, bc the way you do it is you throw away half the array at a time
	- there are certain situations where you can use 3 cases...ie if you somehow have a characteriziation that can immediately tell you if mid is smallest
		- ie in this problem!
		- but typically, the characterization only tells you which half the mid could belong too
- if you're trying to find specific target, then you can still use 2 cases; but can also do 3 cases, to possibly end iteration quicker



# Results





# Todo

## explanation
- array is pretty much sorted, so makes sense to see if a binary search technique would work
- need to figure out: given a (sub)array containing the solution (the min), how do we decide which half the pick/toss, based on l,m,r?
	- looking at diagram: can kind of see what this looks like
		- ie general intuition for what conditions should be
	- (from this point: there are multiple ways you can define conditions for keep/toss)
		- (there's probly a 'key idea' that is shared among all the different ways to define conditions)
		- (todo..find this 'key idea'; probly can figure it out by staring at the diagram)
		- (after a find the key idea, still keep the examples of 'typical constraints' that ppl use from these ideas)

## return mid
- (bonus realization) we have a property that characterizes the solution:
	- (ie that the solution is at mid)
	- `nums[mid-1] > nums[mid]`
	- this check can be done in O(1), which means we can do a 3 case variant of binary search



## to naming
- imo keep including all variants in problems
	- there aren't that many problems in the grand scheme of things
	- after a few months, it'll feel like second nature



- decide whether code for diff variants is actually needed..ie is it worth ‘practicing’ the diff variants
	- or is it enough to just describe the variants in the ‘binary search’ problem
	- maybe not needed, see next point
	- actually...imo keep variants; can be helpful to contrast to later problems, that cannot use all variants: then it helps me really understand, why we cant use other variants
	- ie similar to logic for why i think its helpful to put all solutions that are optimal in some way; and then understand why similar problems can only use a subset of the approaches

- note: binary search is such an important technique to know (ie apparently for many companies, ie google, its by far the most common topic)
	- a better approach might be: just add a ton of examples of binary search problems that can only use 1 specific template of binary search (ie need to use a specific exit conditio and specifically either 2 or 3 cases, but not both)



## explanation
- is it actually ‘correct/helpul’ to think of this problem as 2 cases:
	- ie: ‘not rotated’ vs ‘rotated’ case
	- (using fact that all unique entires), you can perform this check via: 
		- rotated iff nums[0] > nums[-1] 
			- bc nums[0] comes after nums[-1] in the og sorted array 
		- equivalently: sorted IFF nums[0] < nums[-1]
- need to more clearly explain why the above check, also holds for subarrays
	- tbh this is not immediately obvious to me




## result
- are there similarities to a diff problem (figure out what problem im talking about here)
	- ie, should this cite that problem (or vice versa?)
	- that problem was like:
		- pick a half
		- check that half
		- use the check decide which half to do analysis on
			- iirc, we were checking which half was sorted
		- do analysis on that other half
			- iirc, point was that it’s easier to analyze the sorted half
		- then decide which half to toss
	- it seems like that other problem is a more complicated variant: ie not only do you run a check to decide which half to toss; but you also run a check to decide, which half should i run the check on...
	- so it seems that problem, should cite this problem




## reference

- to binary search
	- meat of every technique: which half of the search space should we eliminate?
		- find the correct jargon for this step, it must exist
		- i’m currently using ‘mid-adjustment’
	- surely there’s generalizations of ‘binary search’
		- ie general idea is: ‘narrowing the search space’
		- might be interesting to look for similar/more general techniques/problems
		- ie sometimes: instead of checking things to figure out a solution; think about, how can we check things, to eliminate most things as a solution
			- two pointer is another example of this

- binary search is probly ALWAYS about figuring out which half to throw away
	- 2 vs 3 cases is just about: is there a relatively efficient routine to determine if mid is the solution

## 2vs 3 cases
- wait..notice something:
	- the ‘check if mid is solution’ looks very similar to the 2 element case
		- is there a general relationship here? 
		- actually..i feel like no..

- i wonder if 2 vs 3 cases has a very general approach:
	- figure out what characterizes a solution
		- i highly suspect this is actually always possible
		- i highly suspect it is: ‘compute a key for mid and mid-1’, and then compare their values
		- then 2vs 3 cases is: how efficient is it to compute this key, relative to rest of algo
		- here, it is very efficient, bc key is element itself
		- but some probsl ike ‘koko bananas’, it is relatively inefficient...so you do 2 cases
	- if what i wrote above is true...then 2 vs 3 cases, isnt actually a ‘technique variant’
		- similar to how ‘run check on left vs right’ doesnt seem like a ‘technique variant’




- confirm: this problem you can actually do 3 cases
	- the ‘return mid’ case: nums[mid-1] > nums[mid]
	- aka there actually is a ‘property’ of the solution, that is relatively efficient to check


## result: it can matter which half you 'run check on'
- maybe this problem should be the fp for this ‘run check on left vs right’ subtlety
	- in general: the idea is that we pick one of the halves to check: and if it sorted, then we throw it away, bc the other half contains the pivot
		- the only case where this fails, is if the whole array is sorted; in this case, we want to keep the left half
	- this means that: if we ‘run check on left’, then we also need to check if the full array is sorted (otherwise general idea above is incorrect)
	- but ‘run check on right’ doesnt need this ‘full array check’, bc even in the ‘full array sorted’ case, it does the right thing



---


- in the 2 element case: you actually dont necessarily know which element is the pivot; could be first or second
	- so in this case, you just make sure to return the smaller element
- actually NO: in 2 element case:
	then you figure out, which one is the mid
	- i suspect: if you ‘check right’, then mid is left, ie [mid=left, right]
	- if you ‘check left, then mid is right..ie [left, mid=right]
- and then now, you can see what your algo does based on the cases...what will it set mid to

if sorted: then you want to pick left. (aka throw away right)
if rotated: then you want to pick right. (aka throw away left)

ok step 1: confirm that in 2 element case: the whole array will be the ‘subarray’.
then step 2: see what ‘check left’ would return, vs ‘check right’

assuming my step 1 above is correct:
then ‘check left’:
if sorted: throws away left. incorrect!
if rotated: keeps left: (incorrect!)
but check right:
if sorted: throws away right. correct.
if rotated: keeps right. correct.


i highly suspect this is a major lesson..this should be the fp atm for this
aka fp: pay attention to the 2 element case!!


## reference

- to binary search
	- it seems: focusing on how your loop handles the ‘2 element subarray’ case, is probably the best way to figure out the finer details
		- ie do you set mid to left or right element (ie what do you want to return)
		- do you return mid+1? (i think this is a thing i saw in some places)

## result: matters to focus on left or right
- probably need a fp about ‘it matters whether you focus on left or right subarray’
	- what i mean:
		- wlog this algo, runs a check on the left subarray, to determine whether to throw away itself or the right subarray
		- note: symmetric/equivalently, we could’ve ran a (possibly inverted) check on right subarray, to determine which to throw
		- subtlety: these methods might not necessarily be equivalent, once you get the 2 element subarray case
		- ie every case, you probably want to make sure that both approaches are throwing away the same subarray
		- but in 2 subarray case: they likely throw away different things, bc we’re at a base case rn
		- this might be fine, but it probably means that this also changes what you need to pick in this base case...
		- i suspect: both cases are correct, but point is, this leads to variations of code, so make sure you focus on 2 element case to figure out the details
		- imo: this type of variant (do we run check on left or right) isn’t actually a ‘diff technique’; ie there arent going to be problems where you can only do check on one of the options
			- however: i still do think there should prob be a fp that discusses this, bc its important...and probably this discussjon is what leads to the tip of ‘make sure you focus on 2 element case’


## to todo
- binary search
	- don’t spend too much time on each binary search, trying to find perfect writeup
	- apparently this is one of the harder topics (ie phd students dont write bug free code)
		- imo a big reason is because the finer details matter a lot (ie while loop exit conditions; 2 vs 3 cases)
	- instead: just review a ton of examples, so then the patterns become obvious to me
		- ie binary search is not like other techniques, where: ‘if you know the general idea’, then you will easily figure out the finer details
	- ie cover problems that help me figure out exactly the differences between the variants/subtleties














# Implementations
## Binary search
- implementations
	- iterative: 2 case, strict exit
	- recursive
	- bisect
	- iterative: 3 case, weak exit


```

"""iterative"""
class Solution:
    def findMin(self, nums: List[int]) -> int:
        start , end = 0, len(nums) - 1 
        curr_min = float("inf")
        
        while start  <  end :
            mid = start + (end - start ) // 2
            curr_min = min(curr_min,nums[mid])
            
            # right has the min 
            if nums[mid] > nums[end]:
                start = mid + 1
                
            # left has the  min 
            else:
                end = mid - 1 
                
        return min(curr_min,nums[start])


"""recursive"""
class Solution:    
    def findMin(self, nums):
        def dfs(start, end):
            if end - start <=  1:
                return min(nums[start], nums[end])

            mid = (start + end)//2
            if nums[end] < nums[mid]:
                return dfs(mid + 1, end)
            elif nums[end] > nums[mid]:
                return dfs(start, mid)

        return dfs(0, len(nums) - 1)


"""bisect"""

class Solution:
    def findMin(self, nums):
        self.__getitem__ = lambda i: nums[i] <= nums[-1]
        return nums[bisect.bisect(self, False, 0, len(nums))]


"""3 cases"""
class Solution:
    def findMin(self, nums: List[int]) -> int:
        if len(nums) == 1 or nums[0] < nums[-1]:
            return nums[0]

        left, right = 0, len(nums) - 1
        while left <= right:
            mid = left + (right - left) // 2
            if mid > 0 and nums[mid - 1] > nums[mid]:
                return nums[mid]
            if nums[mid] > nums[right]:
                left = mid + 1
            else:
                right = mid - 1
```


![](../!assets/attachments/Pasted%20image%2020240310195718.png)




- characterizing the solution
	- if subarray is not been rotated:
		- (check this via `nums[0] < num[-1]`)
		- then it's just `nums[0]`
	- if subarray has been rotated:
		- for any subarray containing the solution: it is the first number that's less than or equal to the end of the subarray
- base cases
	- `end - start <= 1` means that we have interval of length `1` or `2`, so we can directly check minimum.
- mid adjustment
	- if `nums[end] < nums[mid]`, this means that minimum we are looking for is situated in the right half.
	- elif `nums[end] > nums[mid]` means that minimum we are looking for is situated in the left half.

we set end/high/right = mid, because mid could be the minimum; so we want to keep it in the range


- complexity
	- time O(log n)


---

- another way for characterizing solution:
	- The key to solving this problem lies in understanding how a rotation affects a sorted array. Despite the rotation, a portion of the array remains sorted. If the array is not rotated or has been rotated a full cycle (n times), then the smallest element would be at the beginning. If it is rotated, the array is composed of two increasing sequences, and the minimum element is the first element of the second sequence.
	- Therefore, we can use binary search to quickly identify the point where the transition from the higher value to the lower value occurs, which indicates the smallest element. The binary search is modified here to compare the middle element with the first element and decide where to move next:

---

![](../!assets/attachments/Pasted%20image%2020240310204423.png)


---

![](../!assets/attachments/Pasted%20image%2020240310204331.png)

---

![](../!assets/attachments/Pasted%20image%2020240310204259.png)

---

actually..
![](../!assets/attachments/Pasted%20image%2020240310204038.png)
![](../!assets/attachments/Pasted%20image%2020240310204149.png)



![](../!assets/attachments/Pasted%20image%2020240310204215.png)




(nvm, see above) can you compare with left instead?
![](../!assets/attachments/Pasted%20image%2020240310204006.png)
![](../!assets/attachments/Pasted%20image%2020240310203949.png)

---

```
# if nums[mid] > nums[right], we KNOW that the
# pivot/minimum value must have occurred somewhere to the right
# of mid, which is why the values wrapped around and became smaller.
# ie nums[right] is less then nums[mid]


# otoh, if nums[mid] <= nums[right]:
# we KNOW the pivot must be at mid or to the left of mid:
# if nums[mid] <= nums[right], we KNOW that the pivot was not encountered
# to the right of middle, because that means the values would wrap around
# and become smaller (which is caught in the above if statement).
# this leaves the possible pivot point to be at index <= mid.

# note it is possible for the mid index to store a smaller
# value than at least one other index in the list (at right), so we do
# not discard it by doing right = mid - 1. it still might have the minimum value.

# left and right converge to a single index (for minimum value) since
# our if/else forces the bounds of left/right to shrink each iteration
```


![](../!assets/attachments/Pasted%20image%2020240310203908.png)




this cpp soln is different? he's checking if it's rotated inside the while loop

![](../!assets/attachments/Pasted%20image%2020240310194254.png)



- variant
	- note: you can actually do 3 cases
		- bc you can actually characterize the min:
			- (ie not just characterize what half it is in)
			- If `nums[mid-1] > nums[mid]` then `nums[mid]` is the minimum
		- then the other 2 cases for halves:
			- If `nums[mid] > nums[right]` then search on the right side, because smaller elements are in the right side
			- Else search on the left side.



- note: apparently you don't actually need to handle the "edge case" (no rotation)
	- depends on if you think 'non rotated array' has a higher probability than usual, of being the input

```
class Solution:
    def findMin(self, nums: List[int]) -> int:
        left = 0
        right = len(nums) - 1
        
        while left <= right:
            mid = (left + right) // 2
            
            if mid > 0 and nums[mid-1] > nums[mid]:
                return nums[mid]
            
            if nums[mid] > nums[right]:
                left = mid + 1
            else:
                right = mid - 1
        return nums[mid]
```


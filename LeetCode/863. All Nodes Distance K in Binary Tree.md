[863. All Nodes Distance K in Binary Tree](https://leetcode.com/problems/all-nodes-distance-k-in-binary-tree/)

```python
# Definition for a binary tree node.
# class TreeNode:
#     def __init__(self, x):
#         self.val = x
#         self.left = None
#         self.right = None

class Solution:
    def distanceK(self, root: TreeNode, target: TreeNode, k: int) -> List[int]:
        
```

# Description

Given the `root` of a binary tree, the value of a target node `target`, and an integer `k`, return _an array of the values of all nodes that have a distance_ `k` _from the target node._

You can return the answer in **any order**.

**Example 1:**  
![](!assets/attachments/Pasted%20image%2020240426153950.png)  
**Input:** `root = [3,5,1,6,2,0,8,null,null,7,4], target = 5, k = 2`  
**Output:** `[7,4,1]`  
**Explanation:** The nodes that are a distance 2 from the target node (with value 5) have values 7, 4, and 1.  

**Example 2:**  
**Input:** `root = [1], target = 1, k = 3`  
**Output:** `[]`  

**Constraints:**
- The number of nodes in the tree is in the range `[1, 500]`.
- `0 <= Node.val <= 500`
- All the values `Node.val` are **unique**.
- `target` is the value of one of the nodes in the tree.
- `0 <= k <= 1000`

---


# References
## #trees/no_pointers_to_parent 
- to manually construct this:
	- i think you can use either bfs/dfs?
	- store in dict, where TreeNode is type of both key and value


- even if you can use any traversal, seems pre-order dfs is most sensible; ie aligns most with what we want to compute via the traversal
	- ie parent, then left child, then right child) and assigns the current node's parent to it in the dictionary.


- understanding when it's 'helpful' to construct mapping to parents
	- you're essentially creating an implicit graph
	- aka you're saying that your problem is easier to solve if you can view it as a graph problem


- understanding when you 'need' to construct mapping to parents
	- aka there are other problems where you don't need this..you can like 'implicitly' return to parents via 'recursion'
		- i think the key is that in those questions: when you 'go back to parents', this is all happening in like 'one pass'...or 'only once'...or idk really how to explain this
		- versus here...the 'intuitive' way to solve this (ie start at node, and then traverse outward), the required traversal just seems too complicated to handle via recursion alone

---

wait...(see ref below)
- !!! is it true that you basically should never actually need 'parent' pointers?
	- ie maybe this problem might be actually one of the best ways to realize this, if this is true
	- at the very least, if your problem is basically about paths...then need to remember key fact about trees: fairly certain that, not just only 1 path btwn nodes; but also that, this path will only have 1 change of direction


## #backtracking 

the 'dfs' here sounds more like 'backtracking'; aka make/unmake on 'visited nodes' along path
	aka dfs is 'required ' implicitly, bc backtracking

1. **Performing the Search**: Once we have the ability to move both up and down the [tree](https://algo.monster/problems/tree_intro), we perform a [depth-first search](https://algo.monster/problems/dfs_intro) (DFS) starting from the target node. As we explore the tree, we keep track of the current distance from the target. When this distance equals **k**, we add the current node's value to our answer.
    
2. **Avoiding Revisits**: To ensure we don't count any nodes twice or enter a loop, we keep a set of visited nodes. Whenever we visit a node, we add it to the set. If we encounter a node that's already in our set, we skip it.


Inside the DFS function, we first ensure that the current node is not `None` and hasn't been visited yet, as indicated by checking the `vis` set. If we have seen the node already, we return early to avoid revisiting it.
	- it seems common thing in backtracking:
		- to handle 'non valid neighbors': it might be easier/cleaner to implement via 'base case' at the top of the routine;
			- instead of having a routine/conditionals that determine whether you call dfs on neighbors or not, based on whether they are 'valid routes for exploration'


1. **Base Case for Distance**: If the distance `k` is 0, it means we have found a node at the exact distance from the target we are looking for, so we append the value of the current node to the `ans` list, which will eventually be our output.

(explore neighbors)
1. **Recursive Case for Traversal**: If k is not 0, we recursively call DFS on the left child, the right child, and the parent of the current node, each time with `k - 1` to account for the decrease in distance as we move one step away from the target.



## tbd ('path btwn nodes in tree has only 1 direction change')

- https://en.wikipedia.org/wiki/Tree_(graph_theory)
	- a **tree** is an [undirected graph](https://en.wikipedia.org/wiki/Undirected_graph "Undirected graph") in which any two [vertices](https://en.wikipedia.org/wiki/Vertex_(graph_theory) "Vertex (graph theory)") are connected by _exactly one_ [path](https://en.wikipedia.org/wiki/Path_(graph_theory) "Path (graph theory)")

actually the property i'm looking for is more like, 'any path in tree can only have 1 change in vertical direction property'..iirc i've definitely seen this in a different problem before

this seems like a competitive programming type thing...check halim...
#/cite


- examples
	- https://leetcode.com/problems/all-nodes-distance-k-in-binary-tree/solutions/163101/Java-Solution/
		- solution 1
	- https://leetcode.com/problems/all-nodes-distance-k-in-binary-tree/solutions/143798/1ms-beat-100-simple-java-dfs-with-without-hashmap-including-explanation/
		- space complexity is basically dfs complexity
		- Great solution. Thanks for sharing. We can also improve the time complexity a little bit, since we don't need to continue to search if the distance length from target to current node keep increasing, and it is larger than K. The following shows the sample code.


**Idea**

- Note the distances from target node to all the nodes up the path to root from target in a map.
- Apply pre-order traversal using the map above.
    - If the node is present in the map, use that distance
    - else assume `d+1` where d = distance for the parent.


As we know, if the distance from a node to target node is `k`, the distance from its child to the target node is `k + 1` **unless** the child node is closer to the target node which means the target node is in it's subtree.

To avoid this situation, we need to travel the tree first to find the path from `root` to `target`, to:

- store the value of distance in hashamp from the `all nodes in that path` to `target`

Then we can easily use dfs to travel the whole tree. Every time when we meet a treenode which has already been stored in map, use the stored value in hashmap **instead of** plus 1.

Time Complexity: O(n)


# Strategies




## backtracking on implicit graph
- strat
	- step 1: parent pointers
	- step 2: backtrack to find distance k


- complexity
	- time O(n)
	- 
1. The function `parents` traverses the entire tree to build a dictionary `p` mapping each node to its parent. This is a depth-first search (DFS) with a single visit to each node, hence its complexity is `O(N)`, where `N` is the number of nodes in the tree.
2. The function `dfs` is a recursive depth-first search. In the worst case, it can visit each node once when `k` equals the height of the tree. Additionally, it might visit each node's parent, resulting in `O(2N)` operations, which simplifies to `O(N)`.


space: O(n) for parent; and i think O(k) for everything else? (not O(n) like algomonster says below...) 

1. The `p` dictionary holds a pair for each node in the tree, hence `O(N)` space.
2. The `ans` list could hold up to `N` nodes (in the case that the tree is a straight line and `k` equals `N-1`), so its space is `O(N)`.
3. The call stack for the DFS function can go up to the height of the tree in the case of a skewed tree, which in the worst case is `O(N)`.
4. The `vis` set contains nodes that are already visited, which in the worst case can be `O(N)` as well when every node is visited.

The space complexity is determined by adding the space required for the `p` dictionary, the `ans` list, the call stack, and the `vis` set, which all contribute linearly to `O(N)` space.


```python
class Solution:
10    def distanceK(self, root: TreeNode, target: TreeNode, k: int) -> List[int]:
11        # Helper function to store parent pointers for each node
12        def map_parents(node, parent):
13            if node:
14                parent_map[node] = parent
15                map_parents(node.left, node)
16                map_parents(node.right, node)
17
18        # Helper function to perform Depth-First Search (DFS) and find nodes at distance k
19        def find_nodes_at_distance_k(node, remaining_distance):
20            if not node or node.val in visited:
21                return
22            visited.add(node.val)
23            if remaining_distance == 0:
24                result.append(node.val)
25            else:
26                # Visit children and parent
27                find_nodes_at_distance_k(node.left, remaining_distance - 1)
28                find_nodes_at_distance_k(node.right, remaining_distance - 1)
29                find_nodes_at_distance_k(parent_map[node], remaining_distance - 1)
30
31        # Initialize the parent map and result list
32        parent_map = {}
33        result = []
34        visited = set()
35
36        # Map parents for all nodes in the tree
37        map_parents(root, None)
38
39        # Start DFS from the target node
40        find_nodes_at_distance_k(target, k)
41
42        return result
```


```python
class Solution:
    def distanceK(self, root: TreeNode, target: TreeNode, k: int) -> List[int]:
        def parents(root, prev):
            nonlocal p
            if root is None:
                return
            p[root] = prev
            parents(root.left, root)
            parents(root.right, root)

        def dfs(root, k):
            nonlocal ans, vis
            if root is None or root.val in vis:
                return
            vis.add(root.val)
            if k == 0:
                ans.append(root.val)
                return
            dfs(root.left, k - 1)
            dfs(root.right, k - 1)
            dfs(p[root], k - 1)

        p = {}
        parents(root, None)
        ans = []
        vis = set()
        dfs(target, k)
        return ans
```



### optimization
- i'm pretty sure this code is same, it's just:
	- in a tree, unique path btwn nodes
	- so you don't actually need to store the full 'visited' nodes
		- just need to know the previous node we came from


```python
class Solution:
    def distanceK(self, root: TreeNode, target: TreeNode, k: int) -> List[int]:
        def dfs1(root, fa):
            if root is None:
                return
            p[root] = fa
            dfs1(root.left, root)
            dfs1(root.right, root)

        def dfs2(root, fa, k):
            if root is None:
                return
            if k == 0:
                ans.append(root.val)
                return
            for nxt in (root.left, root.right, p[root]):
                if nxt != fa:
                    dfs2(nxt, root, k - 1)

        p = {}
        dfs1(root, None)
        ans = []
        dfs2(target, None, k)
        return ans
```


## 'tree path property'

```python
def dfs(self,res,node,target,K,depth):
        if node is None:
            return 0
        if depth == K:
            res.append(node.val)
            return 0
        if node.val == target or depth > 0:
            left = self.dfs(res, node.left, target, K, depth + 1)
            right = self.dfs(res, node.right, target, K, depth + 1)
        else:
            left = self.dfs(res, node.left, target, K, depth)
            right = self.dfs(res, node.right, target, K, depth )

        if node.val == target:
            return 1
        if left == K or right == K:
            res.append(node.val)
            return 0

        if left > 0:
            self.dfs(res, node.right, target, K, left + 1)
            return left + 1
        if right > 0:
            self.dfs(res, node.left, target, K, right + 1)
            return right + 1
        return 0



    def distanceK(self, root,target,k):
        res = []
        if k == 0:
            res.append(target.val)
        else:
            self.dfs(res,root,target,k,0)

        return res
```
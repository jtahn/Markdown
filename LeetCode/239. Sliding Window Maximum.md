[239. Sliding Window Maximum](https://leetcode.com/problems/sliding-window-maximum/)

You are given an array of integers `nums`, there is a sliding window of size `k` which is moving from the very left of the array to the very right. You can only see the `k` numbers in the window. Each time the sliding window moves right by one position.

Return _the max sliding window_.

**Example 1:**  
**Input:** `nums = [1,3,-1,-3,5,3,6,7], k = 3`  
**Output:** `[3,3,5,5,6,7]`  
**Explanation:**  
```
Window position                Max
---------------               -----
[1  3  -1] -3  5  3  6  7       **3**
 1 [3  -1  -3] 5  3  6  7       **3**
 1  3 [-1  -3  5] 3  6  7      ** 5**
 1  3  -1 [-3  5  3] 6  7       **5**
 1  3  -1  -3 [5  3  6] 7       **6**
 1  3  -1  -3  5 [3  6  7]      **7**
```

**Example 2:**  
**Input:** `nums = [1], k = 1`  
**Output:** `[1]`  

**Constraints:**
- `1 <= nums.length <= 10^5`
- `-10^4 <= nums[i] <= 10^4`
- `1 <= k <= nums.length`

---

# todo/Reflections/for future me when i'm ready
- note that [42. Trapping Rain Water](42.%20Trapping%20Rain%20Water.md) also has both monotone stack and dynamic programming as optimal solutions
	- if you consider 'dynamic programming' = 'two pointer'...
	- what is simiilar/different about these problems
	- what is siimlar/different about these techniques


# Brute force
- for each window, compute max in the window
- complexity
	- O(nk) time
		- for each n-k elements, scan k elements to find max of the window

# max heap
```
from heapq import *

class Solution:
    def maxSlidingWindow(self, nums: List[int], k: int) -> List[int]:
        
        H = []
        ans = []
        
        for i in range(k):
            heappush(H,[-nums[i],i])
        
        ans.append(-H[0][0])
        
        for i in range(k,len(nums)):
            heappush(H,[-nums[i],i])
            
            while H and i - H[0][1] >= k:
                heappop(H)
            
            ans.append(-H[0][0])
        
        return ans
```

- one bottleneck in brute force, is the computation of the max
	- is there a way to do this faster?
	- fastest would be max heap
		- but issue with max heap: how do we delete the left pointer stuff
- if your structure exactly contains elements in the window, then that means every time window shifts, you need to figure out where the left node is
	- (so our structure is size k)
	- max heap is not good for this
		- this is O(k)
	- binary search tree is better for this
	- so that's why observation:
		- maybe allow structure to not exactly contain elements in the window?
			- deque: carry less
			- better max heap: carry more...
- observation
	- issue with heap is that: not rly an efficient way to delete the node that's exiting the window
		- way to get around this: observe we only have to delete the node if it the max, otherwise nbd if it's still there
		- so the solution: store not just the value, but the index: so we can quickly check if max value is outside window
	- note: it is NOT true that search/delete is O(log n), despite 'binary' heap
		- !! binary heap and binary search tree have DIFFERENT inequality relations
			- heap property: parent greater than children
				- this tells you nothing about where your node is
				- literally all it is helpful for is finding the max, that's literally it
			- binary search tree: left child <= parent <= right child
				- this relationship is what leads to O(log n) search/delete
- seems that generally, heaps are assumed to be binary heaps
	- ie python implementation is binary heap
	- wiki says common implementation is binary heap
- implementation
	- the while loop: pops max elements that are invalid; ie index is out of the window
		- index of newest node is `i`
		- max node is `H[0]`
			- so `H[0][1]` is its index in the array
		- so `i - H[0][1] >= k` checks whether the current max value is actually outside the window
		- if so, we pop it
			- and we keep doing this as needed
		- once while loop ends, we know the current heap max is in the window
- complexity
	- time O(n log n)
		- note maxheap has no required max size; it only pops if top is outside bounds, but there's no reason this needs to happen
		- ie we'd get a maxheap with the entire sequence if it is an increasing sequence
			- bc we never need to pop; bc the max is always in the window
		- so worst case assume maxheap is size n
			- in which case, operations are O(log n)
	- space
		- O(n)



# Self-balancing BST
```
class Solution {
    public int[] maxSlidingWindow(int[] arr, int k) {
        int n = arr.length, j = 0;
        int[] ans = new int[n - k + 1];
        TreeMap<Integer, Integer> bst = new TreeMap<>();
        for (int i = 0; i < n; i++) {
            bst.put(arr[i], bst.getOrDefault(arr[i], 0) + 1);
            if (i + 1 >= k) {
                ans[j++] = bst.lastKey(); // return max element in BST
                removeElement(bst, arr[i+1-k]);
            }
        }
        return ans;
    }
    void removeElement(TreeMap<Integer, Integer> bst, int x) {
        bst.put(x, bst.getOrDefault(x, 0) - 1);
        if (bst.get(x) == 0) bst.remove(x);
    }
}
```

- todo
	- apparently above code only works if the elements in k window are unique as TreeMap is based on Red-Black tree which can't have duplicates
		- what do you do if duplicates?
	- what does self balancing mean
- strategy
	- add right pointer value to bst
	- (find and) delete left pointer value from bst
		- we know value from array
	- find max in bst
- complexity
	- time O(N log k)
		- because each of the above operations of a BST of size k costs O(log k)
	- space O(k)
- observations
	- basically, this is like a balance btwn 'quickly find max' and 'quickly find node to delete'
		- we sacrifice O(1) computation of max, so that "deleting node" is gauranteed O(log n)


# Decreasing deque (best)
```
from collections import deque

"""cleanest"""
class Solution:
    def maxSlidingWindow(self, nums, k):
        deq, n, ans = deque([0]), len(nums), []

        for i in range (n):
            while deq and deq[0] <= i - k:
                deq.popleft()
            while deq and nums[i] >= nums[deq[-1]] :
                deq.pop()
            deq.append(i)
            
            ans.append(nums[deq[0]])

		# note the first k entries in ans correspond to
		# maxes of windows that are smaller than size k
		# because of how we looped above
        return ans[k-1:]        


"""shorter"""
class Solution:
    def maxSlidingWindow(self, nums: List[int], k: int) -> List[int]:
        q = deque() # stores *indices*
        res = []
        for i, cur in enumerate(nums):
            while q and nums[q[-1]] <= cur:
                q.pop()
            q.append(i)
            # remove first element if it's outside the window
            if q[0] == i - k:
                q.popleft()
            # if window has k elements add to results (first k-1 windows have < k elements because we start from empty window and add 1 element each iteration)
            if i >= k - 1:
                res.append(nums[q[0]])
        return res
```

![](../!assets/attachments/Pasted%20image%2020240306122140.png)




- one of the observations here
	- assume window is sliding left to right
		- then incoming number is from the right
		- then the structure does not need to keep all window elements
			- if the incoming number is larger than prev numbers; then because of the way we're iterating/analyzing/sliding the window, we know those previous numbers have no chance of being the max in the current and future windows
		- more generally: its because: for all future windows to be scanned, if the 'previous numbers' are there, then so will the incoming number
- jargon that is typically used for this
	- monotonic (increasing) queue
	- decreasing deque
		- a deque is a data structure that allows insertion and deletion from both the front and the back in `O(1)` time complexity
- Sliding window minimum/maximum = monotonic queue
	- The key why monotonic deque works is it stores both magnitude and position information. From head to tail, the elements get smaller and further to the right of the array.
- monotonic queue involves 3 operations
	- pop; aka discard left pointer
		- the only index that might corresp to index of left pointer, is exactly the left-most thing in the deque
			- so we check if its the left pointer; if not, there's nothing to discard/pop
	- push: add right pointer
		- not only do we add it; we also discard non maxes in the window
			- aka anything in the deque that is smaller than the right pointer
		- ie we also discard stuff that is smaller
		- ie keep popping from the right if smaller than right pointer
		- this process is O(1) amortised
	- peek
		- aka tell us the max
		- deque ordered by max
		- which means, left pointer is also the index of max in the window
	- importantly
		- these 3 operations are all O(1)
		- these are the only ops we need for this problem
	- apparently: using a monotonic queue has a very established sequence for each iteration: can either:
		- push,peek,pop
		- pop,push,peek
		- pop,
		- they're all the same..only diff, slight modification to stuff before and after the loop...
- complexity
	- O(n) time
		- since each element is processed (add/remove) at most twice.
		-  The algorithm is amortized O(n) as each element is put and polled once.
		- each element in the original array can only be pushed into and popped out of the deque only once.
	- O(k) space



- In the deque, we add and remove indices.
	- Basically, for each element `nums[i]` in the array that we are about to insert, we first check whether the leftmost index in the sliding window is out of bound. If so, we remove it in constant time.
	- Then we continuously remove the rightmost indices if their corresponding elements are less than `nums[i]` (the element we are about to insert). The idea is that the elements that are less than the element we'll insert won't have any contributions to the maximum element of the sliding window. So it is safe to remove them.
- monotonic deque properties:
	- elements are in decreasing order
- push
	- to enforce monotonic property: means that to push an element into the deque, we first pop everything smaller than it out of the deque


- deque properties/rules:
	- decreasing order
	- only contain elements from the last sliding window (not necessary all elements)
	- the above two imply that:
		- largest element in sliding window is the first element in deque
	- summary
		- Keep indexes of good candidates in deque d. The indexes in d are from the current window, they're increasing, and their corresponding nums are decreasing. Then the first deque element is the index of the largest window value.
- better names
	- right pointer = incoming number
- strategy
	- deque lets us pop from the left O(1) for when a number no longer within, aka exits our sliding window
	- after the pop: the left most value is the largest value in the window
- space complexity
	- O(k) for the deque
	- O(n-k) for output array


- errors
	- forgetting `while q ...`
		- ie forgetting to check the queue exists/is not empty (to prevent popping from an empty q)
	- ![](../!assets/attachments/Pasted%20image%2020240306155855.png)


# Dynamic programming (also best)
```
public int[] maxSlidingWindow(int[] nums, int k) {
  // assume nums is not null
  if (nums.length == 0 || k == 0) {
    return new int[0];
  }
  int n = nums.length;
  int[] result = new int[n - k + 1]; // number of windows
  
  // left & right
  int[] left = new int[n];
  int[] right = new int[n];
  left[0] = nums[0]; // init
  right[n - 1] = nums[n - 1];
  
  for (int i = 1; i < n; ++i) {
    // left
    if (i % k == 0) left[i] = nums[i];
    else            left[i] = Math.max(left[i - 1], nums[i]);
    // right
    int j = n - i - 1;
    if (j % k == (k - 1)) right[j] = nums[j];
    else                  right[j] = Math.max(right[j + 1], nums[j]);
  }
  
  // dp
  for (int i = 0, j = i + k - 1; j < n; ++i, ++j) {
    result[i] = Math.max(right[i], left[j]);
  }
  
  return result;
}

```


![](../!assets/attachments/Pasted%20image%2020240306204950.png)

![](../!assets/attachments/Pasted%20image%2020240306214122.png)

- one way to interpret this (but is not really an inspo):
	- max over an array can an array is equal to
		- max of maxes of subarrays, where the subarrays cover the array
			- (ie they dont have to be disjoint subarrays...but for efficiency, probly dont want to be computing maxes of disjoint subarrays)
	- partition array into windows of size k
		- then any window intersects with most 2 elements of the partition
			- ie the intersections are highlighted in blue and yellow in the picture
			- max of blue part
				- is also equal to "current max during leftward pass in that window"
			- max of yellow part
				- is also equal to "current max during rightward pass in that window"
	- so that's why we get
		- max of the window = max(  right(i), left(i+w-1)  )

- complexity
	- O(n) time
	- O(n) space


![](../!assets/attachments/Pasted%20image%2020240306205122.png)






---


![](../!assets/attachments/Pasted%20image%2020240306205005.png)

![](../!assets/attachments/Pasted%20image%2020240306205158.png)

![](../!assets/attachments/Pasted%20image%2020240306205258.png)


![](../!assets/attachments/Pasted%20image%2020240306205217.png)

![](../!assets/attachments/Pasted%20image%2020240306205040.png)


![](../!assets/attachments/Pasted%20image%2020240306205045.png)
- https://leetcode.com/problems/sliding-window-maximum/solutions/66023/on-solution-cutting-the-array-into-segments-explanation-and-c-implementation/



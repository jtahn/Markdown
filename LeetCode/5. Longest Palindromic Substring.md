[5. Longest Palindromic Substring](https://leetcode.com/problems/longest-palindromic-substring/)

```python
class Solution:
    def longestPalindrome(self, s: str) -> str:
        
```

# Description

Given a string `s`, return _the longest palindromic substring_ in `s`.

A **substring** is a contiguous **non-empty** sequence of characters within a string.

**Example 1:**  
**Input:** `s = "babad"`  
**Output:** `"bab"`  
**Explanation:** `"aba" is also a valid answer.`

**Example 2:**  
**Input:** `s = "cbbd"`  
**Output:** `"bb"`  

**Constraints:**
- `1 <= s.length <= 1000`
- `s` consist of only digits and English letters.

---


# todo

#/move
- make sure i go through and submit solutions to check for optimal
	- leetcode does not always have asymptotically optimal
	- ie [[5. Longest Palindromic Substring]]


#/fundy 
- should i find fundies for all these data structures?
	- https://en.wikipedia.org/wiki/Template:CS_trees
	- https://en.wikipedia.org/wiki/List_of_data_structures
	- find other stuff that isn't on this list? ie it doesnt include
		- https://en.wikipedia.org/wiki/Palindrome_tree
			- - [Eertree (or palindromic tree). Today I want to talk about a data… | by Alessio Piergiacomi | Medium](https://medium.com/@alessiopiergiacomi/eertree-or-palindromic-tree-82453e75025b)
		- but that's probly bc...basicaly no use cases.


#/todo 
- figure out the dp approach to this problem
- how does the 'clever iteration' approach handle even vs odd palindrome?


#/fundy 
- bc of how the 'clever iteration' approach resulted in both pruning + efficient subroutine
	- i wonder if this is like a general pattern that happens very often?
		- specifically, efficient subroutine might mean that you can also prune a lot
		- maybe if the 'check is super simple':
			- it's might often be because: the way you iterate is by continuously traversing/expanding something 'valid' until it becomes invalid
			- and then move to the next 'base case candidate' where you can start 'expanding valid stuff' again


#/todo 
- figure out the complexity benefits from clever iterating
	- i think both fundeez actually contribute
	- the #iteration/for_subroutine benefit is obvious
	- i think the #iteration/for_pruning , you need to do some kind of amortized analysis:
		- there's surely asymptotic complexity benefits bc either:
			- for each center, iterations must do either:
				- end earlier bc fail palindrome check
				- start later bc currMaxLength


# References


## #iteration/for_subroutine 
- for the 'iterate on centers' approach: essentially means that the 'check if palindrome' subroutine is now O(1), bc we're just checking if new endpoints are the same char
	- instead of iterating through the entire string


- the problem with naive iteration:
	- to check for palindrome, it's a linear time subroutine
	- but with clever iteration: it's now constant time



- it seems this is actually the key idea
	-  bc a lot of the 'pruning' optimizations below can be done with naive iteration too



## #iteration/for_pruning 
- note this solution is not a #iteration/two-pointer 
	- so imo, #iteration/for_pruning  and #iteration/for_subroutine are key generalizations of the ideas used in #iteration/two-pointer 
	- but #iteration/two-pointer is still worth specifically discussing, bc it seems like such a major way that these fundeez are used

- here:
	- for each center, expand in both directions
		- instead of 'naive' way where you just iterate over left and right endpts
		- this also makes palindrome checks incredibly efficient, aka #iteration/for_subroutine 
	- this leads to pruning:
		- once palindrome check fails: then don't need to expand anymore



- we also have typical pruning that is available to us, even in naive iteration
	- aka pruning based on the fact that we already know these candidates won't result in a max/min
	- specifically:
		- the first width you try at a center, can start at the currMaxLength
			- although tbh this isn't that big a speedup
			- 'expanding a palindrome' is essentially running the palindrome check
		- do not need to start at centers where max width would be less than currMaxLength
- maybe #/fundy: when doing some kind of 'extrema' problem:
	- no matter how you iterate, you can often at least prune stuff based on the fact that it's size already guarantees it can't be a max/min








# Results



## #strings/manacher

- [Longest palindromic substring - Wikipedia](https://en.wikipedia.org/wiki/Longest_palindromic_substring)
- [Manachar’s Algorithm Tutorials & Notes | Algorithms | HackerEarth](https://www.hackerearth.com/practice/algorithms/string-algorithm/manachars-algorithm/tutorial/)
- [Manacher's Algorithm - Finding all sub-palindromes in O(N) - Algorithms for Competitive Programming](https://cp-algorithms.com/string/manacher.html)

- imo idk if this is actually something i need to know how to code, bc seems applications are sooo limited...aka seems it literally only applies to palindromes
	- but i should DEFINITELY be aware of it and the vague idea behind it




# Approaches


## #dynamic_programming 
- https://www.geeksforgeeks.org/longest-palindromic-subsequence-dp-12/
	- goes through top down and bottom up
- https://algo.monster/liteproblems/5
	- bottom up





## iterate for subroutine + pruning

- my voice memos are just saying, this is 'iterating to simplify that subroutine'
	- aka to make the palindrome check trivial






- take a look at comment chain in this neetcode video
	- https://www.youtube.com/watch?v=XYQecbcd6_c&lc=UgzvbuVVX6rkeGPi2Id4AaABAg
	- there is a suggested change about 'res': should instead use pointers to indices, instead of slicing the string
		- however imo this doesnt change complexity bc a 'new max' can only happen at most n times
		- imo bigger issue is thinking about whether pythons len function is actually O(1) or O(n) time
			- probly have a fundy for this
		- also i should probly have a fundy about:
			- complexity of python slicing...since its immutable type, probly means python spends time creating a new object...how inefficient is this practically; but also, how should i theoretically consider the complexity of this operation?
- jargon
	- grind75 puts this problem in their 'string' section
	- neetcode puts the problem in the DP section, but the code below doesnt match up at all with the DP code that other sources provide 
	- 


- in my voice memos, i say that this is about pruning iterations
	- note there are other ways of iterating that would allow this..
	- ie once i find max palindrome from i to j:
		- then for iterating over starting with i+1:
		- i can just immediately start with substring going to j-1
		- ie if we had abcdcba
			- then iteration starting with letter b:
			- can just start with bcdcb
	- tho tbh...this doesnt seem that great...but i bet manacher kinda uses this observation...



```python
class Solution:
    def longestPalindrome(self, s: str) -> str:
        res = ""
        resLen = 0

        for i in range(len(s)):
            # odd length
            l, r = i, i
            while l >= 0 and r < len(s) and s[l] == s[r]:
                if (r - l + 1) > resLen:
                    res = s[l : r + 1]
                    resLen = r - l + 1
                l -= 1
                r += 1

            # even length
            l, r = i, i + 1
            while l >= 0 and r < len(s) and s[l] == s[r]:
                if (r - l + 1) > resLen:
                    res = s[l : r + 1]
                    resLen = r - l + 1
                l -= 1
                r += 1

        return res

```


## manacher

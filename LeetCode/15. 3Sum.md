[15. 3Sum](https://leetcode.com/problems/3sum/)

```
class Solution:
    def threeSum(self, nums: List[int]) -> List[List[int]]:
        
```

# Description
Given an integer array nums, return all the triplets `[nums[i], nums[j], nums[k]]` such that `i != j`, `i != k`, and `j != k`, and `nums[i] + nums[j] + nums[k] == 0`.

Notice that the solution set must not contain duplicate triplets.

**Example 1:**  
**Input:** `nums = [-1,0,1,2,-1,-4]`  
**Output:** `[[-1,-1,2],[-1,0,1]]`  
**Explanation:**  
```
nums[0] + nums[1] + nums[2] = (-1) + 0 + 1 = 0.
nums[1] + nums[2] + nums[4] = 0 + 1 + (-1) = 0.
nums[0] + nums[3] + nums[4] = (-1) + 2 + (-1) = 0.
The distinct triplets are [-1,0,1] and [-1,-1,2].
Notice that the order of the output and the order of the triplets does not matter.
```

**Example 2:**  
**Input:** `nums = [0,1,1]`  
**Output:** `[]`  
**Explanation:** The only possible triplet does not sum up to 0.  

**Example 3:**  
**Input:** `nums = [0,0,0]`  
**Output:** `[[0,0,0]]`  
**Explanation:** The only possible triplet sums up to 0.  

**Constraints:**
- `3 <= nums.length <= 3000`
- `-10^5 <= nums[i] <= 10^5`

---


# References

## check collisions via set
- check if solution already found
	- aka existence
	- aka set
	- note: ‘same’ solution: can be any order
	- so need to pick a ‘key’ you store for each solution
		- ie ‘representative for equivalent things’’
		- standard choice: sorted tuple
		- (btw: is ‘key’ the correct jargon? aka what do you call elements of a set)



# Results

## handling duplicate solutions by TBD

!!! this is the conclusion imo

- summary:
	- the approach is simply, to iterate in a way that let's you skip duplicate searches
		- bc duplicate search would duplicate the solution
	- there's surely many ways to 'iterate' this, so "2-pointer" isn't actually the inspo here
		- but i could mention: equivalent intuition for this approach is: '2-pointer on sorted subproblems'



- i decided to move 'sort then subproblems' into the first type of approach
	- it's true, 2pointer can be considered an 'optimization' of this
	- but imo, I think it's more helpful to think of this as a different approach to how you handle duplicates

- maybe the way you distinguish why its slightly different from 2pointer:
	- 2pointer: skipping things bc you know it cant be the solution
	- here: skipping things bc you've already done it
		- ie: it is a solution
		- and it also means that: the optimization we do here, means that there is a separate routine/task that be entirely deleted, even for the iterations we do visit
		- ie don't even run an existence check anymore, for iterations we do process
		- vs every other 2 pointer problem: you still do the same routine; its just now you skip iterations

- btw: imo 'iterate' is the right word here
	- the scenario is that:
		- we want all possible solutions in the search space
		- so naturally...iterate through entire search space and check if it's a solution


---

- meta
	- this could be sconsidered 2-pointer, bc throwing away iterations
	- but i feel like this is different flavor...bc we're doing it here to 'skip duplicates
	- maybe cite 2-pointer here
	- this problem is doing something that's simultaenously more fundamental and more specific than 2-pointer
		- 2- pointer skips iterations bc they're 'useless', often I already know we can't beat current stuff
		- here: we skip iterations also bc useless...but bcI know it's going to duplicate...
		- yea this is more specific than 2 pointer
	- i think what I mean by 'this scenario is more fundamental'
		- we have underlying reasoning for why we sort ahead of time
		- bc the 'first question' is like: can we iterate in a way that allows us to guarantee unique solutions
			- so this is the true inspo imo
			- so maybe this problem is like:
				- pre-process in a way that makes it clear how to throw away iterations
				- and in this: to skip duplicates...
			- man there's just such a big jump here rn..i think leave this to be inducted on later...
	- what do i say for 'TBD'
		- imo 'sort, then iterating cleverly' is too specific
- -

---

- intuition for how to 'figure out how to iterate, then skip?'
	- standard approach:
		- organize search space in a certain way...that mirrors how you check for duplicates
		- so that 'adjacent iterations', it's much easier to tell if it's a duplicate
	- oh it's obvoius:
		- organize search space so that duplicate searches are adjacent
		- point being: if element is the same, then so is the result/key



---


- do some preprocessing and/or iterate in a way, that guarantees that if we find a solution, it’s unique
- possible intuition here:
	- think about what the key/representatives look like for idea 1
	- see if you can modify the input so that computed solutions are always exactly the ‘representative’
	- so here: representative is sorted tuple; so lets just sort the input
		- and then skip iterations when it’s ‘same element as prev iteration’
		- imo: ‘skip iterations’ might actually be a separate key idea..ie there’s like a mini ‘2 pointer’ fundy going on here


- idea???/future: this idea, maybe there’s a more fundy observation...bc the ‘sort array at the start’ enables not only ‘easy to determine duplicates’, but also ‘skip iterations’
	- tbh: ‘skip iterations’ is really the thing here..this is whats allowing us to ‘not do a duplicate check’
	- so imo..this truly is like a ‘2 pointer idea’ going on here (separate from the fact that we 2 pointers to solve the sorted 2sum subproblem)


- need to explain why skipping iterations:
	- guarantees unique
	- doesnt lose solutions
	- aka: only solutions we ‘skip’ are non-unique solutions
	- maybe im thinking about this the wrong way? maybe:
		- observe that we are ‘obviously computing duplicate solutions if we do full iteration
		- then we realize how to iterate more smartly to avoid duplicates
	- so maybe key idea for ‘sorting’:
		- the idea is to preprocess array so that when we compute solutions, it is always the representative
		- maybe this is same complexity as ‘unsorted’ array:
			- todo: compute what the time complexity contribution is for sorting each solution
			- yea, i need to add that time complexity contribution!
			- ehh its negligible tho...for each solution, its log(3)=O(1)...

- what iterations are ‘duplicates’ ie what iterations can we skip
	- for both first and second pointer: only run if this is a unique number for this pointer
		- bc we’ve already run an iteration where wlog, first pointer was at this number
		- (and same arg for second pointer)
	- so above proves that indeed, we are exactly skipping ‘duplicate’ solutions
	- !! the key point is that; bc we presorted array: we know are only computing ‘representative’ solutions
		- then: skipping iterations means we skip all ‘duplicate’ representatives
		- so these 2 facts combined..convincing enough that we exactly compute unique solutions?





# Implementations


## find solutions, then check duplicates
- implementations
	- brute force
		- check each valid triplet
	- unsorted subproblems
		- for each element, solve unsorted 2sum
		- (unsorted) [1. Two Sum](1.%20Two%20Sum.md)
	- sort, then sorted subproblems
		- for each element, solve sorted 2sum
		- (sorted) [167. Two Sum II - Input Array Is Sorted](167.%20Two%20Sum%20II%20-%20Input%20Array%20Is%20Sorted.md)
		- (meta: imo this goes for this approach)
			- the difference btwn this and above:
				- you move the 'representative computation' earlier




```
# Brute force
# time O(n^3)



# subproblems, unsorted
def


# modified implementation bc we want all solutions
# (put above comment right above the 2sum routine)







# subproblems, sorted
def


# modified implementation bc we want all solutions
# (put above comment right above the 2sum routine)


```


### unsorted subproblems

- O(n^3) space
	- memory required for set (for handling duplicates)
	- bc set is not the actual solution, it consumes space complexity
		- need to convert set to a list at the end
	- num of possible solutions is n^3, bc triplets
		- uhh actually TODO: i dont think this is true
	- figure out what actually is the max possible num solutions...there’s no way its possible for every triplet to be a solution, 
	- (but point is: space complexity is noticeable)
	- (btw: theres also space complexity for th 2sum subproblem, bc need a dict there bc unsorted...but its not going to be higher than the ttl problem complexity, so it doesnt matter tbh)


- sort then skip iterations:
	- O(1) space bc the ‘list we’re building’ is ultimately the solution (so is considered O(1))







## pre-process to guarantee unique solutions
- implementations
	- sorted searches
		- ie so duplicate searches are all next to each other



```
class Solution:
    def threeSum(self, nums: List[int]) -> List[List[int]]:
        res = []
        nums.sort()

        for i, a in enumerate(nums):
            # Skip positive integers
            if a > 0:
                break

            if i > 0 and a == nums[i - 1]:
                continue

            l, r = i + 1, len(nums) - 1
            while l < r:
                threeSum = a + nums[l] + nums[r]
                if threeSum > 0:
                    r -= 1
                elif threeSum < 0:
                    l += 1
                else:
                    res.append([a, nums[l], nums[r]])
                    l += 1
                    r -= 1
                    while nums[l] == nums[l - 1] and l < r:
                        l += 1
                        
        return res
```



### 3 pointers
- strategy
	- sort array
	- then iterate over nodes: 
		- for each node, then on rest of the array we are solving a subproblem that is similar to [167. Two Sum II - Input Array Is Sorted](167.%20Two%20Sum%20II%20-%20Input%20Array%20Is%20Sorted.md)
			- ie want to find two numbers that sum to `- (current node)`
			- in general, two pointer is the optimal solution
			- hashmap is also optimal here, because entry values are bounded
				- i.e. technically O(1) space, bc entries have absolute value at most 2 x 10^5
			- (but probly better to use two pointer...its more optimal for the 'unbounded entries' variant of this problem, which seems useful)
- optimization
	- during iteration, break once we reach a positive number: bc we can't sum to zero using numbers after it (bc they are also positive)
- complexity
	- time
		- O(n^2) total
			- O(n logn) to sort 
			- O(n) to loop over nodes
				- for each, another O(n) to solve the "sorted 2sum" subproblem
	- space complexity
		- O(n) if i'm lazy: use a set to store found solutions (this way, no duplicates)
		- O(1) if you iterate in a way that guarantees unique solutions only
			- (can do this bc array is sorted)
			- whenever you finish an iteration for `i`, then you increment `i` until you reach a new value
			- whenever you find a solution, then you increment `l` until you reach a new value
			- observe all solutions satisfy `nums[i] <== nums[l] <= nums[r]`
			- so incrementing i and l in the manner mentioned above, means that subsequent solutions in the inner loop are guaranteed to satisfy second number larger; and subsequent solutions from next iteration of outr loop, have first number larger...
			- ie when you move to the next iteration, you advance iterator/pointers until you actually encounter a new number
			- probably better explanation:
				- if a solution has all diff numbers, then we're guaranteed to find it in the increasing order of numbers...ie `[-3,1,2]` is always found in that order
				- if solution has some repeated numbers...how is duplicating this avoided????
			- nah my original explanation was best; it's basically like 'proof by induction kind of thing'
				- first solution is different from everything after, bc you know either first or second number is strictly larger
				- second solution different from everything after, for the same reason
				- and etc etc
[78. Subsets](https://leetcode.com/problems/subsets/)

```python
class Solution:
    def subsets(self, nums: List[int]) -> List[List[int]]:
        
```

# Description
Given an integer array `nums` of **unique** elements, return _all possible subsets (the power set)_.

A **subset** of an array is a selection of elements (possibly none) of the array.

The solution set **must not** contain duplicate subsets. Return the solution in **any order**.

**Example 1:**  
**Input:** `nums = [1,2,3]`  
**Output:** `[[],[1],[2],[1,2],[3],[1,3],[2,3],[1,2,3]]`  

**Example 2:**  
**Input:** `nums = [0]`  
**Output:** `[[],[0]]`  

**Constraints:**
- `1 <= nums.length <= 10`
- `-10 <= nums[i] <= 10`
- All the numbers of `nums` are **unique**.

---

# References

## python: lists wrt scope
- specifically: inner function can modify list defined in enclosing function
- https://realpython.com/python-scope-legb-rule/#using-the-legb-rule-for-python-scope
- https://realpython.com/inner-functions-what-are-they-good-for/#retaining-state-in-a-closure
	- However, you can also create closures that modify their enclosing state by using mutable objects, such as dictionaries, sets, or lists.
	- aka here: dynamic enclosing state
		- as opposed to "static enclosing state"
- https://www.quora.com/Why-does-Python-let-you-access-a-list-but-not-an-int-from-a-nested-inner-function-Python-function-scope-nested-development
	- You can always access the variables of the outer scope (assuming you haven't shadowed them), but you cannot modify them without first declaring them `nonlocal`. If you don't, an attempt in an inner scope to assign to a name used in the outer scope will only create a new local variable with the same name that now shadows the outer scope variable. Of course, without the `nonlocal` declaration, even though you can't modify an outer variable that points to a list (or other mutable object) by reassigning it to point to a different object, the fact that you can access it means you can still mutate it. Changing the contents of the list doesn't change which list it is.


# Todo

- figure out what exactly: backtracking vs dfs
- then determine whether solution below is backtracking or dfs
	- equivalently, determien whether this problem should be the fundy for backtracking
- atm..seems silly to call it backtracking, when you never 'prune' anything?
	- like it's just dfs...

- nvm...skiena uses this problem as his first example of backtracking
- it seems backtracking doesn't require pruning
	- but often, pruning is what gives backtracking it's power




# Results

## backtracking basics
- not addressed in clrs, but maybe i have wrong jargon..it's surely discussed somewhere
- skiena ch 9 is excellent; delete all the other sources/garbo below lol

![](../!assets/attachments/Pasted%20image%2020240417023452.png)



![](../!assets/attachments/Pasted%20image%2020240417022344.png)
![](../!assets/attachments/Pasted%20image%2020240417022355.png)
![](../!assets/attachments/Pasted%20image%2020240417022407.png)
![](../!assets/attachments/Pasted%20image%2020240417022438.png)


![](../!assets/attachments/Pasted%20image%2020240417022609.png)
![](../!assets/attachments/Pasted%20image%2020240417022636.png)









- https://algo.monster/problems/backtracking
- https://leetcodethehardway.com/tutorials/basic-topics/backtracking
- it's a form of dfs
	- actually, most ppl below say that dfs is a form of backtracking..?
- https://en.wikipedia.org/wiki/Backtracking
- what makes it 'special'/'more specific'/'better' than dfs?
	- is it about memory savings? yea does seem like it
		- I vaguely remember seeing this
			- [22. Generate Parentheses](22.%20Generate%20Parentheses.md)
		- !! probly!
			- https://stackoverflow.com/a/59005494
				- for high-level languages, dfs is essentially backtracking without pruning
				- however for more lower level languages, backtracking is more memory efficient, bc of how you 'store neighbors/adjacency'
			- https://stackoverflow.com/a/49316997
				- dfs is a traversal technique
				- backtracking is a problem solving technique
				- backtracking is 'dfs with pruning'
			- https://cs.stackexchange.com/a/129212
				- backtracking doesn't need to store 'next nodes to visit'
					- dfs does
			- https://dimosr.github.io/backtracking-vs-depth-first-search/
				- backtracking can typically just mutate a 'curr structure'
					- vs dfs repeatedly making copies
		- these ppl probly don't know what they're talking about, but mebe skim anyways
			- https://leetcode.com/discuss/general-discussion/136503/what-is-difference-between-backtracking-and-depth-first-search
			- https://www.reddit.com/r/leetcode/comments/xsesuo/backtracking_vs_dfs/
			- If there are multiple paths to reach node 'A', in backtracking you visit that 'A' node multiple times through different paths. However in DFS you only hit the node once even though there are multiple ways to reach the node. Thus in DFS you don't actually care about the state of the variables in following a particular path in the recursion tree, however, you care about them in the backtracking.
			- 

# Approaches


## 'backtracking' (or dfs?)
- https://leetcodethehardway.com/solutions/0000-0099/subsets-medium#approach-2-backtracking
	- approach 2
- essentially same thing, they don't call it backtracking
	- https://algo.monster/liteproblems/78


```python
class Solution:
    def subsets(self, nums: List[int]) -> List[List[int]]:
        res = []

        subset = []

        def dfs(i):
            if i >= len(nums):
                res.append(subset.copy())
                return
            # decision to include nums[i]
            subset.append(nums[i])
            dfs(i + 1)
            # decision NOT to include nums[i]
            subset.pop()
            dfs(i + 1)

        dfs(0)
        return res

```
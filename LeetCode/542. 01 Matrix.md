[542. 01 Matrix](https://leetcode.com/problems/01-matrix/)

```python
class Solution:
    def updateMatrix(self, mat: List[List[int]]) -> List[List[int]]:
        
```

# Description

Given an `m x n` binary matrix `mat`, return _the distance of the nearest_ `0` _for each cell_.

The distance between two adjacent cells is `1`.

**Example 1:**  
![](../!assets/attachments/Pasted%20image%2020240224223053.png)  
**Input:** `mat = [[0,0,0],[0,1,0],[0,0,0]]`  
**Output:** `[[0,0,0],[0,1,0],[0,0,0]]`  

**Example 2:**  
![](../!assets/attachments/Pasted%20image%2020240224223102.png)  
**Input:** `mat = [[0,0,0],[0,1,0],[1,1,1]]`  
**Output:** `[[0,0,0],[0,1,0],[1,2,1]]`  

**Constraints:**
- `m == mat.length`
- `n == mat[i].length`
- `1 <= m, n <= 10^4`
- `1 <= m * n <= 10^4`
- `mat[i][j]` is either `0` or `1`.
- There is at least one `0` in `mat`.

---

# todo

#/style
- description heading
	- don't have to scroll all the way back up to read again
	- also on chromebook/ipad: mobile app, it's difficult to scroll up perfectly at the start, without bringing up the command palette


#/style  
- my current jargon:
	- inspiration/key idea:
		- is what I choose as the ‘seed’ idea, the ‘starting observation’
		- the 'best' intuition/definition
	- intuition is more general/different
		- basically, always a high-level understanding of what the code is doing
		- aka 'equivalent definition/explanation'
		- but intuition that isnt 'inspo', is bc I dont feel it fits in the general framework/landscape of 'problem solving'
			- ie isnt enough of an example of a 'pattern'necessarily the best way to 


#/meta
- when revising a ton of assorted/messy/long thoughts
	- (also just a very general workflow; applies not just do other obsidian docs, but my thesis/vscode as well)
	- use nested headings to split and summarize ideas
	- then it's far easier to:
		- identify the 'order of where things go'
		- move related things near each other
	- which then makes it far easier to revise






# References
## #graphs/complexity_of_traversal
- (todo: find a trustworthy reference that confirms this)
- BFS complexity on a graph is O(E+V)
- here, E=4V (each cell has 4 neighbors, ie each vertex has 4 edges)
- so complexity is O(5V) = O(V) = O(mn)




## #graphs/start_traversal_on_base_cases 
- observe: solution at node depends on solutions at neighbors
	- is it more specific than this? ie depends on extrema of neighbors?
- probly equivalent but less fundy interpretations:
	- why bfs is used for when we want to min/max
	- use bfs when the 'edges/leafs' are the only places we can immediately compute solution
		- ie extreme nodes
- this particular problem, you need to use bfs for this technique
	- will we always need bfs if we 'start on base cases'? i don't think so...



## #graphs/traversal/bfs 
- for every node, compute distance; and distance based on 'levels'
	- this is classic bfs





# Strategies

## compute distance from neighbors


### bfs initialized at every node

- run a BFS on every node
- $O(n^2 m^2)$ time: BFS is  $O(mn)$ , and need to run it for each node (count  $nm$ )
-  $O(nm)$  space: a queue for the BFS (can be reset after each completed BFS), and for an array to save min distances for each nodes



- maybe intuition about when to use BFS/DFS: if a node’s answers can be generated from immediate neighbors
	- and if generating/computing requires/depends on iterating in a particular way: then this is probly what forces choices like BFS/DFS and pre/in/post-order



- probly make a simple general/inductive arg: 
	- need to keep in mind: arg needs to mention the fact that we want to find min distance...and this should lead to why we need to use BFS
	- inductive arg probly like: assuming we alrdy found all nodes with min distance at most k; then unvisited neighbors are all nodes with min distance k+1



### bfs initialized at water nodes
- in brute, when we did BFS on every node: we do a lot of redundant work
- bc if all of a node’s neighbors have found their answers, then this node’s answer is just 1+the min of neighbors


- so now think about the base case: what nodes can we immediately compute answer, without knowing neighbors?
	- this is exactly the water nodes
- then: if we know all water answers: what can we compute next?
	- all of they’re neighbors, aka coast nodes




- so from this: now we see ‘intuition’: we should start on water nodes...
	- aka initialize stack with all the 0s



```
def updateMatrix(self, mat: List[List[int]]) -> List[List[int]]:
    n,m = len(mat), len(mat[0])
    queue = []
    queue = collections.deque(queue)
    for i in range(n):
        for j in range(m):
            if mat[i][j] == 0:
                queue.append((i,j))
    while queue:
        r,c = queue.popleft()
        for neighbor in [(r-1,c),(r+1,c),(r,c-1),(r,c+1)]:
            i,j = neighbor
            if 0<=i<n and 0<=j<m and mat[i][j]==1:
                mat[i][j] = mat[r][c]-1
                queue.append((i,j))
    for i in range(n):
        for j in range(m):
            mat[i][j] *= -1
    return mat
```

- strategy
	- initialize queue with the 0 cells
	- for each pop:
		- check if neighbors (if they exist, ie in bounds) have unknown distance
		- if unknown: then neighbor.distance = cell.distance + 1
- complexity
	- O(mn) space because of the queue
	- O(nm) time
- Optimizations
	- keeping track of visited nodes without creating a separate data structure:
		- observe that "valid neighbor" can include neighbor.value=1
		- so then just set `neighbor.value = -neighbor.distance = -cell.distance-1`
			- need to do negative, bc need cells w/ distance 1 to be invalid after we explore them
		- and then after BFS, go through array and switch to positive
		- this doesn't change asymptotic time complexity...but compared to rest of the algo, this isn't a trivial operation either...aka there definitely is a time tradeoff here




## taxicab distance
- implementations
	- dynamic programming
- prose
	- distance = x distance plus y distance
	- this means that distance to nearest 0 node: can do this by:
		1. compute smallest x distances
		2. using those numbers: compute smallest y distances.
	- todo: figure out good explanation for why: computing this distance can be done by 'find smallest x distance, then from there compute smallest y distance'
- complexity
	- Time O(nm)
	- Space O(1)


```
# passes along each dim, that compute smallest distance along that dim


def


	- do passes along dim 0 that compute smallest x distance
	- then do passes along dim 1 that add the smallest y distance



# N,S,E,W passes


def


# SE pass; then NW

def


```


### clean up
note: both of the following code examples are NOT what i have in mind, wrt strategy above
the output is equivalent, but the passes are not done in the way i say above
(aka i want code that aligns with the actual reason/intuition for why this method works)
ie i'm thinking of passes that are like: N,S; then E,W

but below:
![](../!assets/attachments/Pasted%20image%2020240224223559.png)
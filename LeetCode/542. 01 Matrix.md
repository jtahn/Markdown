[542. 01 Matrix](https://leetcode.com/problems/01-matrix/)

Given an `m x n` binary matrix `mat`, return _the distance of the nearest_ `0` _for each cell_.

The distance between two adjacent cells is `1`.

**Example 1:**  
![](../!assets/attachments/Pasted%20image%2020240224223053.png)  
**Input:** `mat = [[0,0,0],[0,1,0],[0,0,0]]`  
**Output:** `[[0,0,0],[0,1,0],[0,0,0]]`  

**Example 2:**  
![](../!assets/attachments/Pasted%20image%2020240224223102.png)  
**Input:** `mat = [[0,0,0],[0,1,0],[1,1,1]]`  
**Output:** `[[0,0,0],[0,1,0],[1,2,1]]`  

**Constraints:**
- `m == mat.length`
- `n == mat[i].length`
- `1 <= m, n <= 10^4`
- `1 <= m * n <= 10^4`
- `mat[i][j]` is either `0` or `1`.
- There is at least one `0` in `mat`.

---

# todo
- the observation that you can ‘flip the problem’:
	- this isn’t actually the ‘seed’
	- the ‘seed’:
		- in brute, when we did BFS on every node: we do a lot of redundant work
		- bc if all of a node’s neighbors have found their answers, then this node’s answer is just 1+the min of neighbors
	- so many intuition about when to use BFS/DFS: if a node’s answers can be generated from immediate neighbors
		- and if generating/computing requires/depends on iterating in a particular way: then this is probly what forces choices like BFS/DFS and pre/in/post-order
		- so now think about the base case: what nodes can we immediately compute answer, without knowing neighbors?
			- this is exactly the water nodes
		- then: if we know all water answers: what can we compute next?
			- all of they’re neighbors, aka coast nodes
		- probly make a simple general/inductive arg: 
			- need to keep in mind: arg needs to mention the fact that we want to find min distance...and this should lead to why we need to use DFS
			- inductive arg probly like: assuming we alrdy found all nodes with min distance at most k; then unvisited neighbors are all nodes with min distance k+1
	- so from this: now we see ‘intuition’: we start on water nodes...
		- but point is: they wasn’t actually the ‘inspo’...
		- and it’s not really ‘flipping the problem’...
- to blurb:
	- inspiration/key idea: is like the ‘seed’ idea, the ‘starting observation’
	- intuition is different imo: this isn’t necessarily the “seed”, but more a high-level understanding of what the code is doing
	- kinda like: inspiration=’best definition’; intuition=’equivalent definitino’


# Brute force search (via BFS)
- run a BFS on every node
- $O(n^2 m^2)$ time: BFS is  $O(mn)$ , and need to run it for each node (count  $nm$ )
-  $O(nm)$  space: a queue for the BFS (can be reset after each completed BFS), and for an array to save min distances for each nodes

# BFS (called once)
```
def updateMatrix(self, mat: List[List[int]]) -> List[List[int]]:
    n,m = len(mat), len(mat[0])
    queue = []
    queue = collections.deque(queue)
    for i in range(n):
        for j in range(m):
            if mat[i][j] == 0:
                queue.append((i,j))
    while queue:
        r,c = queue.popleft()
        for neighbor in [(r-1,c),(r+1,c),(r,c-1),(r,c+1)]:
            i,j = neighbor
            if 0<=i<n and 0<=j<m and mat[i][j]==1:
                mat[i][j] = mat[r][c]-1
                queue.append((i,j))
    for i in range(n):
        for j in range(m):
            mat[i][j] *= -1
    return mat
```
- idea
	- "flip" the problem: ie start on 0s instead of 1s
- strategy
	- initialize queue with the 0 cells
	- for each pop:
		- check if neighbors (if they exist, ie in bounds) have unknown distance
		- if unknown: then neighbor.distance = cell.distance + 1
- complexity
	- O(mn) space because of the queue
	- O(nm) time
		- (todo: find a trustworthy reference that confirms this)
		- BFS complexity on a graph is O(E+V)
		- here, E=4V (each cell has 4 neighbors, ie each vertex has 4 edges)
		- so complexity is O(5V) = O(V) = O(mn)
- Optimizations
	- keeping track of visited nodes without creating a separate data structure:
		- observe that "valid neighbor" can include neighbor.value=1
		- so then just set `neighbor.value = -neighbor.distance = -cell.distance-1`
			- need to do negative, bc need cells w/ distance 1 to be invalid after we explore them
		- and then after BFS, go through array and switch to positive
		- this doesn't change asymptotic time complexity...but compared to rest of the algo, this isn't a trivial operation either...aka there definitely is a time tradeoff here

# Dynamic programming
- observations
	- distance = x distance plus y distance
	- this means that distance to nearest 0 node: can do this by:
		1. compute smallest x distances
		2. using those numbers: compute smallest y distances.
	- todo: figure out good explanation for why: computing this distance can be done by 'find smallest x distance, then from there compute smallest y distance'
- strategy
	- do passes along dim 0 that compute smallest x distance
	- then do passes along dim 1 that add the smallest y distance
- complexity
	- Time O(nm)
	- Space O(1)


todo: add code.
note: both of the following code examples are NOT what i have in mind, wrt strategy above
the output is equivalent, but the passes are not done in the way i say above
(aka i want code that aligns with the actual reason/intuition for why this method works)
ie i'm thinking of passes that are like: N,S; then E,W

but below:
![](../!assets/attachments/Pasted%20image%2020240224223559.png)